{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parent_directory = os.path.split(os.getcwd())[0]\n",
    "# sys.path.insert(0, parent_directory)\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "from gnss_lib_py.io.android import make_gnss_dataframe\n",
    "from gnss_lib_py.io.nmea import NMEA\n",
    "from gnss_lib_py.core.measures import FindSat, expected_measures, correct_pseudorange\n",
    "from gnss_lib_py.core.constants import GPSConsts\n",
    "from gnss_lib_py.algorithms.snapshot import solve_pos\n",
    "from gnss_lib_py.io.android import make_gnss_dataframe\n",
    "from gnss_lib_py.core.coordinates import ecef2geodetic\n",
    "from gnss_lib_py.core.ephemeris import EphemerisManager"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# e.g. DATA_PATH = \"/home/user/data/Google/training/\"\"\n",
    "DATA_PATH = os.path.join(parent_directory, \"data/training/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# used for receiver clock bias estimation\n",
    "\n",
    "def least_squares(x_0,bu,sat_df,pranges):\n",
    "    \"\"\"\n",
    "    input(s)\n",
    "        x:  [3 x 1] state estimate\n",
    "        bu: clock bias\n",
    "        sat_df: satellite data frame\n",
    "        pranges: psudoranges\n",
    "    output(s)\n",
    "        bu: new clock bias\n",
    "    \"\"\"\n",
    "    numSats = len(sat_df)\n",
    "    dist = np.zeros((numSats,1))\n",
    "\n",
    "    G = np.zeros((numSats,4))\n",
    "    W = np.eye(numSats)\n",
    "    for ii in range(numSats):\n",
    "        x_s = sat_df[\"x\"].to_numpy()[ii]\n",
    "        y_s = sat_df[\"y\"].to_numpy()[ii]\n",
    "        z_s = sat_df[\"z\"].to_numpy()[ii]\n",
    "\n",
    "        dist[ii] = np.sqrt((x_s-x_0[0])**2 + \\\n",
    "                           (y_s-x_0[1])**2 + \\\n",
    "                           (z_s-x_0[2])**2)\n",
    "        G[ii,:] = [-(x_s - x_0[0])/dist[ii],\n",
    "                   -(y_s - x_0[1])/dist[ii],\n",
    "                   -(z_s - x_0[2])/dist[ii],\n",
    "                   1.0]\n",
    "        W[ii,ii] *= 1./pranges[ii]\n",
    "\n",
    "    rho_0 = dist + bu\n",
    "    rho_dif = pranges.reshape(-1,1) - rho_0\n",
    "    delta = np.linalg.pinv(W.dot(G)).dot(W).dot(rho_dif)\n",
    "    bu_new = bu + delta[3,0]\n",
    "    return bu_new"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def calc_residuals(trace_name, phone_type, verbose = False):\n",
    "    \"\"\"Calculate residuals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trace_name : string\n",
    "        Provided name for trace, e.g., \"2020-05-14-US-MTV-1\".\n",
    "    phone_type : string\n",
    "        Type of phone used to record data, e.g., \"Pixel4\", \"Pixel4XL\",\n",
    "        \"Pixel4XLModded\", \"Mi8\".\n",
    "    verbose : bool\n",
    "        If true, prints debugging statements\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Analyzing trace \",trace_name,phone_type,\"...\")\n",
    "\n",
    "    constants = GPSConsts()\n",
    "\n",
    "    manager = EphemerisManager(DATA_PATH)\n",
    "\n",
    "    span_gt_filepath = os.path.join(DATA_PATH, trace_name,\n",
    "                                    \"SPAN_\" + phone_type + \"_10Hz.nmea\")\n",
    "\n",
    "    # load measurements\n",
    "    input_filepath = os.path.join(DATA_PATH, trace_name,\n",
    "                                  phone_type + \"_GnssLog.txt\")\n",
    "    measurements, android_fixes = make_gnss_dataframe(input_filepath, True)\n",
    "\n",
    "    print(\"Successfully loaded \", measurements.shape[0], \" measurements\")\n",
    "    print(\"Successfully loaded \", android_fixes.shape[0], \" android fixes\")\n",
    "\n",
    "    utc0 = int(measurements[\"utcTimeMillis\"].iloc[0])\n",
    "    measurement_date = datetime.datetime.fromtimestamp(utc0/1000.0)\n",
    "\n",
    "    # load ground truth\n",
    "    nmea_obj = NMEA(span_gt_filepath)\n",
    "    gt_ecef, gt_times, gt_lla = nmea_obj.ecef_gt_w_time(measurement_date.date())\n",
    "\n",
    "    gt_lla = np.array(gt_lla)\n",
    "    print(\"Successfully loaded \",gt_lla.shape[0],\" ground truth points.\")\n",
    "\n",
    "    gt_utc_time_millis = np.array(gt_times) * 1000\n",
    "\n",
    "    # temp shorten dataframe\n",
    "    gtimes = 1000\n",
    "    measurements = measurements.head(gtimes)\n",
    "\n",
    "    # initialize position solution\n",
    "    nr_lla = []\n",
    "    nr_ecef = []\n",
    "    meas_times = []\n",
    "    gt_ecef_alligned = []\n",
    "    gt_lla_alligned = []\n",
    "    receiver_clock_bias = []\n",
    "\n",
    "    residual_data = {}\n",
    "\n",
    "    for e, data in measurements.groupby('Epoch'):\n",
    "        if e % 100 == 0:\n",
    "            print(\"e: \",e)\n",
    "        epoch_all = measurements.loc[(measurements['Epoch'] == e)]\n",
    "\n",
    "        # drop duplicates\n",
    "        epoch = epoch_all.drop_duplicates(subset='SvName')\n",
    "\n",
    "        timestamp = epoch.iloc[0]['UtcTimeNanos'].to_pydatetime(warn=False)\n",
    "        epoch.set_index('SvName', inplace = True)     # changes dataframe indexing to satellite-based indexing (Really neat!)\n",
    "        epoch.sort_index(inplace = True) # sorts rows by index\n",
    "        sats = epoch.index.unique().tolist()\n",
    "        if len(sats) < 4:\n",
    "            continue\n",
    "        ephemeris = manager.get_ephemeris(timestamp, sats)\n",
    "\n",
    "        # calculate the ground truth location\n",
    "        meas_time = int(epoch['utcTimeMillis'].values[0])\n",
    "        gt_ecef_alligned_point = []\n",
    "        for i in range(3):\n",
    "            gt_ecef_alligned_point.append(np.interp(meas_time,\n",
    "                                                    gt_utc_time_millis,\n",
    "                                                    gt_ecef[:,i]))\n",
    "        gt_ecef_alligned_point = np.array(gt_ecef_alligned_point)\n",
    "\n",
    "\n",
    "        # calculate satellite positions\n",
    "        satpos = FindSat(ephemeris, epoch['tTxSeconds'], epoch['GpsWeekNumber'])\n",
    "        sat_x = satpos[\"x\"].to_numpy()\n",
    "        sat_y = satpos[\"y\"].to_numpy()\n",
    "        sat_z = satpos[\"z\"].to_numpy()\n",
    "\n",
    "        # get psuedorange\n",
    "        pranges = epoch['Pseudorange_meters'].to_numpy()\n",
    "        # correct for satellite clock bias\n",
    "        pranges = correct_pseudorange(epoch['tTxSeconds'],\n",
    "                                      epoch['GpsWeekNumber'],\n",
    "                                      ephemeris,\n",
    "                                      pranges,\n",
    "                                      gt_ecef_alligned_point.reshape(1,-1)\n",
    "                                      )\n",
    "        sat_b = np.zeros(sat_z.shape)\n",
    "\n",
    "        # calculate receiver clock bias\n",
    "        rb = 0.0\n",
    "        for ii in range(20):\n",
    "            rb = least_squares(gt_ecef_alligned_point,rb,satpos,pranges)\n",
    "\n",
    "        # solve for the position\n",
    "        try:\n",
    "            pos_ecef = solve_pos(pranges, sat_x, sat_y, sat_z, rb)\n",
    "        except RuntimeError as err:\n",
    "            print(err)\n",
    "            continue\n",
    "\n",
    "        expected, _ = expected_measures(epoch['GpsWeekNumber'],\n",
    "                                    epoch['tTxSeconds'],\n",
    "                                    ephemeris,\n",
    "                                    gt_ecef_alligned_point.reshape(1,-1),\n",
    "                                    rb,# 0.0 # -sat_b,\n",
    "                                    0.0,\n",
    "                                    np.zeros((1,3)),\n",
    "                                    satpos)\n",
    "\n",
    "        gt_psuedoranges = expected[\"prange\"].to_numpy()\n",
    "\n",
    "        # epoch w/ duplicates removed\n",
    "        gt_psuedoranges_unique = []\n",
    "        for index, ss in enumerate(epoch.index):\n",
    "            gt_psuedoranges_unique.append(gt_psuedoranges[sats.index(ss)])\n",
    "        epoch.loc[:,\"gt_pr\"] = gt_psuedoranges_unique\n",
    "\n",
    "        # calculate residual\n",
    "        epoch.loc[:,\"residual\"] = epoch[\"gt_pr\"] \\\n",
    "                                - pranges\n",
    "\n",
    "        ################################################################\n",
    "        # RECALCULATE RECEIVER CLOCK BIAS\n",
    "        ################################################################\n",
    "\n",
    "        # remove satellites with high residuals to recalculate rb\n",
    "        residual_mean = epoch[\"residual\"].mean()\n",
    "        distance_from_mean = abs(epoch[\"residual\"] - residual_mean)\n",
    "        epoch_rb = epoch[distance_from_mean <= 500]\n",
    "\n",
    "        sats_rb = epoch_rb.index.unique().tolist()\n",
    "        if len(sats_rb) < 4:\n",
    "            continue\n",
    "        ephemeris_rb = manager.get_ephemeris(timestamp, sats_rb)\n",
    "\n",
    "        # calculate satellite positions\n",
    "        satpos_rb = FindSat(ephemeris_rb, epoch_rb['tTxSeconds'], epoch_rb['GpsWeekNumber'])\n",
    "\n",
    "        # get psuedorange\n",
    "        pranges_rb = epoch_rb['Pseudorange_meters'].to_numpy()\n",
    "        # correct for satellite clock bias\n",
    "        pranges_rb = correct_pseudorange(epoch_rb['tTxSeconds'],\n",
    "                                      epoch_rb['GpsWeekNumber'],\n",
    "                                      ephemeris_rb,\n",
    "                                      pranges_rb,\n",
    "                                      gt_ecef_alligned_point.reshape(1,-1)\n",
    "                                      )\n",
    "\n",
    "        # calculate receiver clock bias\n",
    "        rb = 0.0\n",
    "        for ii in range(20):\n",
    "            rb = least_squares(gt_ecef_alligned_point,rb,satpos_rb,pranges_rb)\n",
    "\n",
    "        ################################################################\n",
    "        #\n",
    "        ################################################################\n",
    "\n",
    "        # solve for the position\n",
    "        try:\n",
    "            pos_ecef = solve_pos(pranges, sat_x, sat_y, sat_z, rb)\n",
    "        except RuntimeError as err:\n",
    "            print(err)\n",
    "            continue\n",
    "\n",
    "        # append position\n",
    "        nr_ecef.append(pos_ecef[:3])\n",
    "        nr_lla.append(ecef2geodetic(pos_ecef[:3]))\n",
    "        meas_times.append(meas_time)\n",
    "        gt_ecef_alligned.append(gt_ecef_alligned_point.tolist())\n",
    "        gt_lla_alligned.append(ecef2geodetic(gt_ecef_alligned_point))\n",
    "\n",
    "        expected, _ = expected_measures(epoch['GpsWeekNumber'],\n",
    "                                    epoch['tTxSeconds'],\n",
    "                                    ephemeris,\n",
    "                                    gt_ecef_alligned_point.reshape(1,-1),\n",
    "                                    rb,# 0.0 # -sat_b,\n",
    "                                    0.0,\n",
    "                                    np.zeros((1,3)),\n",
    "                                    satpos)\n",
    "\n",
    "        gt_psuedoranges = expected[\"prange\"].to_numpy()\n",
    "\n",
    "        # epoch w/ duplicates removed\n",
    "        gt_psuedoranges_unique = []\n",
    "        for index, ss in enumerate(epoch.index):\n",
    "            gt_psuedoranges_unique.append(gt_psuedoranges[sats.index(ss)])\n",
    "        epoch.loc[:,\"gt_pr\"] = gt_psuedoranges_unique\n",
    "\n",
    "        # calculate residual\n",
    "        epoch.loc[:,\"residual\"] = epoch[\"gt_pr\"] \\\n",
    "                                - pranges\n",
    "\n",
    "        # plot residual data\n",
    "        for index, ss in enumerate(epoch.index):\n",
    "            elapsed_sec = (meas_time - meas_times[0]) / 1000.\n",
    "            if ss not in residual_data:\n",
    "                residual_data[ss] = [[elapsed_sec,\n",
    "                                      epoch.loc[ss,\"residual\"]]]\n",
    "            else:\n",
    "                residual_data[ss].append([elapsed_sec,\n",
    "                                          epoch.loc[ss,\"residual\"]])\n",
    "\n",
    "        if verbose:\n",
    "            print(epoch[[\"Pseudorange_meters\",\"gt_pr\",\"residual\"]])\n",
    "\n",
    "\n",
    "    nr_lla = np.array(nr_lla)\n",
    "    gt_lla_alligned = np.array(gt_lla_alligned)\n",
    "\n",
    "    residual_fig = plt.figure()\n",
    "    for key, value in residual_data.items():\n",
    "        value = np.array(value)\n",
    "        plt.plot(value[:,0],value[:,1],label=key)\n",
    "\n",
    "    plt.xlabel(\"time [s]\")\n",
    "    plt.ylabel(\"residiual [m]\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt_file = os.path.join(parent_directory, \"notebooks\", trace_name + \"-\" \\\n",
    "             + phone_type + \".png\")\n",
    "\n",
    "    residual_fig.savefig(plt_file,\n",
    "            format=\"png\",\n",
    "            bbox_inches=\"tight\")\n",
    "\n",
    "    plt.ylim(-100,200)\n",
    "    plt_file = os.path.join(parent_directory, \"notebooks\", trace_name + \"-\" \\\n",
    "             + phone_type + \"-zoomed\" + \".png\")\n",
    "\n",
    "    residual_fig.savefig(plt_file,\n",
    "            format=\"png\",\n",
    "            bbox_inches=\"tight\")\n",
    "\n",
    "    plt.close(residual_fig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def main():\n",
    "    ephemeris_data_path = DATA_PATH\n",
    "\n",
    "    # get all trace options\n",
    "    dirs = sorted(os.listdir(DATA_PATH))\n",
    "    \n",
    "    # remove directories that aren't traces\n",
    "    dirs = [x for x in dirs if x != \"igs\" and x != \"nasa\"]\n",
    "\n",
    "    # create a list of all traces with phone types\n",
    "    trace_list = []\n",
    "    for dir in dirs:\n",
    "        phone_types = []\n",
    "        trace_path = os.path.join(ephemeris_data_path,dir)\n",
    "        for file in sorted(os.listdir(trace_path)):\n",
    "            pt = file.split(\"_\")[0] # potential phone type\n",
    "            if pt != \"SPAN\" and pt not in phone_types:\n",
    "                phone_types.append(pt)\n",
    "\n",
    "        for phone_type in phone_types:\n",
    "            trace_list.append((dir,phone_type))\n",
    "\n",
    "#     trace_list = [\n",
    "#         (\"2020-05-14-US-MTV-1\", \"Pixel4XLModded\"),\n",
    "#         (\"2020-05-14-US-MTV-1\", \"Pixel4\"),\n",
    "#         #bad(\"2020-05-14-US-MTV-2\", \"Pixel4XLModded\"),\n",
    "#         #bad(\"2020-05-14-US-MTV-2\", \"Pixel4\"),\n",
    "#         (\"2020-05-21-US-MTV-1\", \"Pixel4XL\"),\n",
    "#         (\"2020-05-21-US-MTV-1\", \"Pixel4\"),\n",
    "#         (\"2020-05-21-US-MTV-2\", \"Pixel4XL\"),\n",
    "#         (\"2020-05-21-US-MTV-2\", \"Pixel4\"),\n",
    "#         (\"2020-05-29-US-MTV-1\", \"Pixel4XLModded\"),\n",
    "#         (\"2020-05-29-US-MTV-1\", \"Pixel4XL\"),\n",
    "#         (\"2020-05-29-US-MTV-1\", \"Pixel4\"),\n",
    "#         #bad(\"2020-05-29-US-MTV-2\", \"Pixel4XL\"),\n",
    "#         #bad(\"2020-05-29-US-MTV-2\", \"Pixel4\"),\n",
    "#         (\"2020-06-04-US-MTV-1\", \"Pixel4XLModded\"),\n",
    "#         (\"2020-06-04-US-MTV-1\", \"Pixel4XL\"),\n",
    "#         (\"2020-06-04-US-MTV-1\", \"Pixel4\"),\n",
    "#         (\"2020-06-05-US-MTV-1\", \"Pixel4XLModded\"),\n",
    "#         (\"2020-06-05-US-MTV-1\", \"Pixel4XL\"),\n",
    "#         (\"2020-06-05-US-MTV-1\", \"Pixel4\"),\n",
    "#         (\"2020-06-05-US-MTV-2\", \"Pixel4XL\"),\n",
    "#         (\"2020-06-05-US-MTV-2\", \"Pixel4\"),\n",
    "#         #bad(\"2020-06-11-US-MTV-1\", \"Pixel4XL\"),\n",
    "#         #bad(\"2020-06-11-US-MTV-1\", \"Pixel4\"),\n",
    "#         (\"2020-07-08-US-MTV-1\", \"Pixel4XLModded\"),\n",
    "#         (\"2020-07-08-US-MTV-1\", \"Pixel4XL\"),\n",
    "#         (\"2020-07-08-US-MTV-1\", \"Pixel4\"),\n",
    "#         #bad(\"2020-07-17-US-MTV-1\", \"Mi8\"),\n",
    "#         #bad(\"2020-07-17-US-MTV-2\", \"Mi8\"),\n",
    "#         (\"2020-08-03-US-MTV-1\", \"Mi8\"),\n",
    "#         (\"2020-08-03-US-MTV-1\", \"Pixel4\"),\n",
    "#         (\"2020-08-06-US-MTV-2\", \"Mi8\"),\n",
    "#         (\"2020-08-06-US-MTV-2\", \"Pixel4XL\"),\n",
    "#         (\"2020-08-06-US-MTV-2\", \"Pixel4\"),\n",
    "#         #bad(\"2020-09-04-US-SF-1\", \"Mi8\"),\n",
    "#         (\"2020-09-04-US-SF-1\", \"Pixel4XL\"),\n",
    "#         #bad(\"2020-09-04-US-SF-1\", \"Pixel4\"),\n",
    "#         #bad(\"2020-09-04-US-SF-2\", \"Mi8\"),\n",
    "#         (\"2020-09-04-US-SF-2\", \"Pixel4XL\"),\n",
    "#         #bad(\"2020-09-04-US-SF-2\", \"Pixel4\"),\n",
    "#     ]\n",
    "\n",
    "    for trace in trace_list:\n",
    "        trace_name, phone_type = trace\n",
    "        calc_residuals(trace_name, phone_type)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "main()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/derek/datasets/google/training/'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13486/451043146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_13486/932554795.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# get all trace options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# remove directories that aren't traces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/derek/datasets/google/training/'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.9 64-bit ('gnss-lib-python-OzQsnAV4-py3.8': poetry)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "interpreter": {
   "hash": "df7db3f633d608aadd819cb981ccd1c363ad4a8c2accf881a9d1d08bab3ec438"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}